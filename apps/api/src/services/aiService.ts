import { GoogleGenerativeAI } from "@google/generative-ai";
import { db, systemSettings } from "../../../../packages/db/src";
import { eq } from "drizzle-orm";

// Load keys from DB or Env
const getApiKeys = async (): Promise<string[]> => {
    try {
        // Try DB first
        const dbKey = await db.query.systemSettings.findFirst({
            where: eq(systemSettings.key, "GEMINI_API_KEY")
        });

        if (dbKey && dbKey.value) {
            console.log("üîë Using GEMINI_API_KEY from Database");
            return dbKey.value.split(",").map(k => k.trim()).filter(k => k.length > 0);
        }
    } catch (e) {
        console.warn("‚ö†Ô∏è Failed to fetch key from DB, falling back to Env:", e);
    }

    // Fallback to Env
    const keys = process.env.GEMINI_API_KEYS || process.env.GEMINI_API_KEY || "";
    return keys.split(",").map(k => k.trim()).filter(k => k.length > 0);
};

let currentKeyIndex = 0;

export const generateText = async (prompt: string): Promise<string> => {
    const keys = await getApiKeys();

    if (keys.length === 0) {
        throw new Error("No GEMINI_API_KEYS found in Database or Environment variables.");
    }

    const maxRetries = keys.length;
    let attempt = 0;

    // Reset index if out of bounds (keys changed)
    if (currentKeyIndex >= keys.length) currentKeyIndex = 0;

    // Helper: Timeout wrapper
    const withTimeout = <T>(promise: Promise<T>, ms: number): Promise<T> => {
        return Promise.race([
            promise,
            new Promise<T>((_, reject) => setTimeout(() => reject(new Error(`Timeout after ${ms}ms`)), ms))
        ]);
    };

    while (attempt < maxRetries) {
        try {
            const key = keys[currentKeyIndex];
            console.log(`üîë Using Gemini Key [${currentKeyIndex + 1}/${keys.length}]: ${key.slice(0, 4)}...`);

            const genAI = new GoogleGenerativeAI(key);

            // User requested "Gemini 2.5 Flash"
            // User requested "Gemini 2.5 Flash"
            const modelName = process.env.GEMINI_MODEL || "gemini-2.5-flash";
            const model = genAI.getGenerativeModel({
                model: modelName,
                generationConfig: {
                    temperature: 0.9, // Creative High to ensuring rewriting
                    topP: 0.95,
                    topK: 40,
                }
            });

            console.log("----------------------------------------------------------------");
            console.log("üöÄ [AI DEBUG] Sending Prompt to", modelName);
            console.log("üìù [AI DEBUG] Prompt Preview:", prompt.substring(0, 500) + "\n...\n" + prompt.slice(-500));
            console.log("----------------------------------------------------------------");

            // Set timeout to 180s (3 minutes) for large context
            const result = await withTimeout(model.generateContent(prompt), 180000);
            const response = await result.response;
            const textResponse = response.text();

            console.log("----------------------------------------------------------------");
            console.log("üì• [AI DEBUG] Received Response Length:", textResponse.length);
            console.log("üìÑ [AI DEBUG] Response Preview:", textResponse.substring(0, 500) + "...");
            console.log("----------------------------------------------------------------");

            return textResponse;
        } catch (error: any) {
            console.error(`‚ùå AI Generation Error (Attempt ${attempt + 1}/${maxRetries}):`, error.message);

            // Check for quota/rate limit errors (429 usually) or Timeout
            if (error.message?.includes("429") || error.status === 429 || error.message?.includes("quota") || error.message?.includes("Timeout")) {
                console.warn("‚ö†Ô∏è Quota exceeded or Timeout. Switching key/Retrying...");
                currentKeyIndex = (currentKeyIndex + 1) % keys.length; // Rotate
                attempt++;
            } else {
                throw error;
            }
        }
    }

    throw new Error("All API keys exhausted or failed.");
};

// ==================== AUTO-CRAWL SPECIFIC FUNCTIONS ====================

class RateLimiter {
    private lastRequestTime = 0;
    private requestCount = 0;
    private readonly RATE_LIMIT_RPM = 10; // Free tier safe limit
    private readonly MIN_DELAY_MS = (60 / this.RATE_LIMIT_RPM) * 1000; // 6000ms

    async enforceRateLimit() {
        const now = Date.now();
        const elapsedSinceLastRequest = now - this.lastRequestTime;

        // Reset counter every minute
        if (elapsedSinceLastRequest > 60000) {
            this.requestCount = 0;
        }

        // If we've hit limit, wait
        if (this.requestCount >= this.RATE_LIMIT_RPM) {
            const waitTime = 60000 - elapsedSinceLastRequest;
            console.log(`‚è≥ Rate limit reached. Waiting ${Math.ceil(waitTime / 1000)}s...`);
            await this.delay(waitTime);
            this.requestCount = 0;
        }

        // Ensure minimum delay between requests
        if (elapsedSinceLastRequest < this.MIN_DELAY_MS) {
            const waitTime = this.MIN_DELAY_MS - elapsedSinceLastRequest;
            await this.delay(waitTime);
        }

        this.lastRequestTime = Date.now();
        this.requestCount++;
    }

    private delay(ms: number): Promise<void> {
        return new Promise(resolve => setTimeout(resolve, ms));
    }

    getStats() {
        return {
            rpm: this.RATE_LIMIT_RPM,
            requestCount: this.requestCount,
            lastRequestTime: this.lastRequestTime
        };
    }
}

const rateLimiter = new RateLimiter();

/**
 * T√≥m t·∫Øt 1 chapter b·∫±ng AI (3-Step Pipeline - Matches Manual Mode)
 */
export const summarizeChapter = async (
    chapterNumber: number,
    title: string,
    content: string
): Promise<string> => {
    // 1. Check Limits & Logs
    await rateLimiter.enforceRateLimit();
    console.log(`[AI-Service] Processing Single-Prompt Pipe-Delimited for: ${title}`);
    console.log(`[AI-Service] Input Content Length: ${content.length}`);
    console.log(`[AI-Service] Input Preview: ${content.substring(0, 200)}...`);

    if (content.length < 500) {
        console.warn(`[AI-Service] Content too short (${content.length}), AI might hallucinate.`);
    }

    try {
        const prompt = `B·∫°n l√† m·ªôt ti·ªÉu thuy·∫øt gia v√† bi√™n t·∫≠p vi√™n t√†i nƒÉng. Nhi·ªám v·ª• c·ªßa b·∫°n l√† L√ÄM M·ªöI (REWRITE) n·ªôi dung vƒÉn b·∫£n g·ªëc b√™n d∆∞·ªõi (ƒë∆∞·ª£c g·ªôp t·ª´ ${title}) ƒë·ªÉ t·∫°o ra m·ªôt b·∫£n t√≥m t·∫Øt ch∆∞∆°ng h·∫•p d·∫´n.

---
üõë **QUY T·∫ÆC B·∫§T KH·∫¢ X√ÇM PH·∫†M**:
1. **KH√îNG ƒê∆Ø·ª¢C COPY** nguy√™n vƒÉn b·∫£n g·ªëc. Ph·∫£i vi·∫øt l·∫°i 100% b·∫±ng gi·ªçng vƒÉn k·ªÉ chuy·ªán (Storytelling) l√¥i cu·ªën, d·ªìn d·∫≠p.
2. **C√î ƒê·ªåNG**: L∆∞·ª£c b·ªè h·ªôi tho·∫°i r∆∞·ªùm r√†, t·∫≠p trung v√†o h√†nh ƒë·ªông c·ªët l√µi.
3. **ƒê·ªäNH D·∫†NG**: Tr·∫£ v·ªÅ 3 ph·∫ßn ri√™ng bi·ªát, ngƒÉn c√°ch nhau b·∫±ng d·∫•u "|||".

---
üìù **N·ªôi Dung G·ªëc**:
${content.substring(0, 100000)}

---
‚ö†Ô∏è **Y√äU C·∫¶U ƒê·∫¶U RA** (Tr·∫£ v·ªÅ ch√≠nh x√°c theo ƒë·ªãnh d·∫°ng b√™n d∆∞·ªõi, kh√¥ng th√™m l·ªùi d·∫´n):

[T√äN CH∆Ø∆†NG (Ng·∫Øn g·ªçn 5-8 t·ª´, kh√¥ng c√≥ s·ªë th·ª© t·ª±)]
|||
[T√ìM T·∫ÆT NG·∫ÆN (3-5 c√¢u c·∫£m nh·∫≠n/ph√¢n t√≠ch s√∫c t√≠ch)]
|||
[N·ªòI DUNG VI·∫æT L·∫†I (Chi ti·∫øt, h·∫•p d·∫´n, t·∫≠p trung h√†nh ƒë·ªông)]

üëá **B·∫ÆT ƒê·∫¶U**:`;

        console.log("üëâ [AI-Service] Generating Pipe-Delimited Output...");
        // Log Input for verification
        console.log("üìù [Input Preview]:", content.substring(0, 500));

        const result = await generateText(prompt);

        // Log Output for verification
        console.log("üìÑ [Output Preview]:", result.substring(0, 500));
        console.log(`‚úÖ [AI-Service] Done. Length: ${result.length}`);

        return result.trim();

    } catch (error: any) {
        console.error("‚ùå Error in AI Pipeline:", error);
        throw error;
    }
};

/**
 * Get rate limit stats
 */
export const getRateLimitStats = () => rateLimiter.getStats();
